{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt #just for visualizing data(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist # import lableled dataset of 28 x 28 pixel images of digits(already classified data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train),(x_test , y_test) = mnist.load_data() # x being image itself in form of pixels and y is classification in terms of digits from 0 to 9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we normalize the data i.e bringing it to scale of 0 and 1 i.e the images are in form of pixel of range 0-255 we convert them into 0 and 1\n",
    "x_train = tf.keras.utils.normalize(x_train , axis = 1) #Here we have 28 * 28 pixels hence axis = 1 means the second 28 elements of 28*28 pixel suppose if shape of image is 10 * 20 axis 0 = 10 and axis 1 = 20\n",
    "x_test = tf.keras.utils.normalize(x_test ,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a model of  basic sequential neural network\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape = (28,28)))# adds a layer of neural network and flatten layer converts the matrix or array of data in one big line of data in this case we have 28 x 28 pixelated images that gets converted into one big line\n",
    "model.add(tf.keras.layers.Dense(128 , activation = 'relu'))#add basic dense layer in neural function where each neuron in a layer is connected to anther layer neuron\n",
    "model.add(tf.keras.layers.Dense(128 , activation = 'relu'))#same layer as above, 128 is units and relu(retify linear unit) is activation function\n",
    "model.add(tf.keras.layers.Dense(10 , activation = 'softmax'))#output layer with 10 neurons softmax adds all neuron adds to one i.e it gives output of clasification in confidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiles the model\n",
    "model.compile(optimizer = 'adam' , loss = 'sparse_categorical_crossentropy' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1875/1875 [==============================] - 17s 8ms/step - loss: 0.0326 - accuracy: 0.9888\n",
      "Epoch 2/4\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0241 - accuracy: 0.9919\n",
      "Epoch 3/4\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0207 - accuracy: 0.9930\n",
      "Epoch 4/4\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0162 - accuracy: 0.9943\n",
      "INFO:tensorflow:Assets written to: handwritten\\assets\n"
     ]
    }
   ],
   "source": [
    "#train the data set\n",
    "model.fit(x_train , y_train , epochs = 4) #epochs is number of iterations\n",
    "model.save('handwritten')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('handwritten') # simply loads the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.1166 - accuracy: 0.9741\n",
      "0.11658020317554474\n",
      "0.9740999937057495\n"
     ]
    }
   ],
   "source": [
    "loss ,accuracy = model.evaluate(x_test , y_test) # performs classification on test sets \n",
    "print(loss) # loss should be low \n",
    "print(accuracy) #accuracy should be high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we provide our own image of handwritten digits to model to test it with looping through file \n",
    "file_looping = '''image_number = 1\n",
    "while os.path.isfile(f\"digits/digit{image_number}.png\"):\n",
    "    img = cv2.imread(f\"digits/digit{image_number}\".png)[:,:,0]\n",
    "    img = np.invert(np.array([img]))\n",
    "    prediction = model.predict(img)\n",
    "    print(f\"The digit is probably a {np.argmax(prediction)}\")\n",
    "    plt.imshow(img[0] ,cmap = plt.cm.binary)\n",
    "    plt.show()\n",
    "    image_number += 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n",
      "The digit is probably a 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = cv2.imread(\"digit11.png\")[:,:,0] #[:,:,0] represents channels and 0 refers to the shape of image as we simpy have detect the form of digit i.e shape\n",
    "img = np.invert(np.array([img]))# we are inverting the array cause it image by default is defined as white on black and we convert it to black on white\n",
    "prediction = model.predict(img)\n",
    "print(f\"The digit is probably a {np.argmax(prediction)}\")# prints the digit classified based on max probability\n",
    "plt.imshow(img[0] ,cmap = plt.cm.binary) #\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
